{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Learning Cache Replacement Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load extract_tar_gz.py\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "EXTENSION = '.tar.gz'\n",
    "BLKPARSE = '.blkparse'\n",
    "\n",
    "\n",
    "def main(input_dir, output_dir):\n",
    "  assert os.path.isdir(input_dir), \"The input directory {} does not exist\".format(input_dir)\n",
    "\n",
    "  input_dir = input_dir.rstrip(\"/\")\n",
    "  if not os.path.isdir(output_dir):\n",
    "    print(\"Creating output directory {}\".format(output_dir))\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "  for file in os.listdir(input_dir):\n",
    "    if not file.endswith(EXTENSION):\n",
    "      continue\n",
    "    \n",
    "    print(\"Extracting and moving {}\".format(file))\n",
    "    execute_command(\"tar -xvzf {}\".format(input_dir + '/' + file))\n",
    "    execute_command(\"mv ./*{} {}\".format(BLKPARSE, output_dir))\n",
    "    \n",
    "\n",
    "def execute_command(command):\n",
    "  os.system(command)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\"--input_dir\", type=str, help=\"the directory containing the tar.gz files\", required=True)\n",
    "  parser.add_argument(\"--output_dir\", type=str, help=\"the directory containing content of the tar.gz files\", required=True)\n",
    "  args = parser.parse_args() \n",
    "  main(args.input_dir, args.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from collections import Counter, deque, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"FIU_raw\"\n",
    "output_dir = \"FIU_trace\"\n",
    "main(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Cache Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum block number\n",
    "maxpos = 1000000000000\n",
    "\n",
    "# Number of features (Recency, Frequency, Block No.)\n",
    "num_params = 3\n",
    "\n",
    "# Cache Size\n",
    "cache_size = 100\n",
    "\n",
    "\n",
    "sampling_freq = cache_size\n",
    "\n",
    "# How many % of cache to use\n",
    "eviction = int(0.7 * cache_size)  \n",
    "\n",
    "# Results\n",
    "lruCorrect = 0\n",
    "lruIncorrect = 0\n",
    "\n",
    "lfuCorrect = 0\n",
    "lfuIncorrect = 0\n",
    "\n",
    "# Variables\n",
    "X = np.array([], dtype=np.int64).reshape(0,num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"DATA/cheetah.cs.fiu.edu-110108-113008.3.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.1)]\n",
    "\n",
    "len(trainBlockTrace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
