{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Learning Cache Replacement Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from collections import Counter, deque, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Cache Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Shehbaz\n",
    "def get_recency(lru, cache):\n",
    "    recency = []\n",
    "    recency_dict = defaultdict(int)\n",
    "    \n",
    "    # Compute the recency order of each page in cache\n",
    "    for time in range(len(lru)):\n",
    "        recency_dict[lru[time]] = time + 1\n",
    "        \n",
    "    for block in cache:\n",
    "        recency.append(recency_dict[block])\n",
    "\n",
    "    return recency\n",
    "\n",
    "def get_frequency(lfu, cache):\n",
    "    frequency = []\n",
    "    \n",
    "    for block in cache:\n",
    "        frequency.append(lfu[block])\n",
    "    return frequency\n",
    "\n",
    "def normalize_columns(input):\n",
    "    return normalize(input, axis=0)\n",
    "\n",
    "def identity(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belady Optimal Algorithm (From Shehbaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def belady_opt(blocktrace, frame):\n",
    "    global maxpos, sequence_data, sequence_length, opt_hitrates\n",
    "    \n",
    "    optimal = defaultdict(deque)\n",
    "    deleted = defaultdict(int)\n",
    "    lfu = defaultdict(int)\n",
    "    lru = []\n",
    "\n",
    "    # Build the whole index for finding optimal eviction ordering\n",
    "    for request_time, block in enumerate(tqdm(blocktrace, desc=\"OPT: building index\")):\n",
    "        optimal[block].append(request_time)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    cache = []\n",
    "    \n",
    "    for request_time, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "        # increase frequency count\n",
    "        lfu[block] +=1\n",
    "\n",
    "        # Remove the block i at time step j from the index\n",
    "        if len(optimal[block]) is not 0 and optimal[block][0] == request_time:\n",
    "            optimal[block].popleft()\n",
    "\n",
    "        \n",
    "        if block in cache:\n",
    "            # Cache Hit\n",
    "            # Update block to MRU position\n",
    "            hit += 1\n",
    "            lru.remove(block)\n",
    "            lru.append(block)\n",
    "            \n",
    "            assert request_time in deleted\n",
    "            \n",
    "            del deleted[request_time]\n",
    "            if len(optimal[block]) is not 0:\n",
    "                deleted[optimal[block][0]] = block\n",
    "                optimal[block].popleft()\n",
    "            else:\n",
    "                deleted[maxpos] = block\n",
    "                maxpos -= 1\n",
    "        else:\n",
    "            # Cache Miss\n",
    "            miss += 1\n",
    "            if len(cache) == frame:\n",
    "                # Cache is full\n",
    "                assert(len(deleted) == frame)\n",
    "                evictpos = max(deleted)\n",
    "        \n",
    "    \n",
    "                cache[cache.index(deleted[evictpos])] = block\n",
    "                lru.remove(deleted[evictpos])\n",
    "                del deleted[evictpos]\n",
    "            else:\n",
    "                # Cache isn't full\n",
    "                cache.append(block)                \n",
    "            \n",
    "            # Add the candidate victim page to the j'th time step\n",
    "            if len(optimal[block]) is not 0:\n",
    "                deleted[optimal[block][0]] = block\n",
    "                optimal[block].popleft()\n",
    "            else:\n",
    "                deleted[maxpos] = block\n",
    "                maxpos -= 1\n",
    "            lru.append(block)\n",
    "        if (request_time + 1) % 10 == 0:\n",
    "          opt_hitrates.append(hit / (hit + miss))\n",
    "\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LFU(blocktrace, frame):\n",
    "    global lfu_hitrates\n",
    "    cache = set()\n",
    "    cache_frequency = defaultdict(int)\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for request_time, block in enumerate(tqdm(blocktrace, desc=\"LFU\")):\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        if block in cache:\n",
    "            hit += 1\n",
    "            cache_frequency[block] += 1\n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] += 1\n",
    "            miss += 1\n",
    "        else:\n",
    "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
    "            cache_frequency.pop(e)\n",
    "            cache.remove(e)\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] = frequency[block]\n",
    "            miss += 1\n",
    "        if (request_time + 1) % 10 == 0:\n",
    "          lfu_hitrates.append(hit / (hit + miss))\n",
    "        \n",
    "    hitrate = hit / ( hit + miss )\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LRU(blocktrace, frame):\n",
    "    global lru_hitrates\n",
    "    cache = set()\n",
    "    recency = deque()\n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    for request_time, block in enumerate(tqdm(blocktrace, desc=\"LRU\")):\n",
    "        \n",
    "        if block in recency:\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            hit += 1\n",
    "        elif len(recency) < frame:\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "        else:\n",
    "            recency.popleft()\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "        if (request_time + 1) % 10 == 0:\n",
    "          lru_hitrates.append(hit / (hit + miss))\n",
    "        \n",
    "    hitrate = hit / (hit + miss)\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23374516\n"
     ]
    }
   ],
   "source": [
    "#train_file = \"FIU_output/casa-110108-112108.4.blkparse\"\n",
    "train_file = \"rl_envs/cheetah.cs.fiu.edu-110108-113008.3.blkparse\"\n",
    "df = pd.read_csv(train_file, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainRaw = df['blockNo'].tolist()\n",
    "print(len(trainRaw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af148fe79d2e4e21a182e1d9d8befc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='LRU', max=50000, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43291f5852e8457ab0d94f11406a6c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='LFU', max=50000, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a5daaf620041dd8b6c7862134172e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT: building index', max=50000, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d33f874f2e84637abed5e672a13da6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=50000, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rl_envs/cheetah.cs.fiu.edu-110108-113008.3.blkparse\n",
      "Cache size: 30\n",
      "OPT: 0.23534\n",
      "LFU: 0.2339\n",
      "LRU: 0.2323\n"
     ]
    }
   ],
   "source": [
    "maxpos = 100000000\n",
    "cache_size = 30\n",
    "#baselines_file = \"baseline_\" + train_file.split(\"/\")[1] + \"-1-{}.pkl\".format(len(trainRaw))\n",
    "baselines_file = \"baseline_C{}\".format(cache_size) + train_file.split(\"/\")[1] + \"-50001-{}.pkl\".format(100000)\n",
    "\n",
    "#trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace) * read_portion)]\n",
    "trainBlockTrace = trainRaw[50000:100000]\n",
    "print(len(trainBlockTrace))\n",
    "\n",
    "lru_hitrates = []\n",
    "lfu_hitrates = []\n",
    "opt_hitrates = []\n",
    "\n",
    "lru_hitrate = LRU(trainBlockTrace, cache_size)\n",
    "lfu_hitrate = LFU(trainBlockTrace, cache_size)\n",
    "opt_hitrate = belady_opt(trainBlockTrace, cache_size)\n",
    "\n",
    "print(train_file)\n",
    "print(\"Cache size: {}\".format(cache_size))\n",
    "print(\"OPT: {}\".format(opt_hitrate))\n",
    "print(\"LFU: {}\".format(lfu_hitrate))\n",
    "print(\"LRU: {}\".format(lru_hitrate))\n",
    "\n",
    "#with open(baselines_file, 'wb+') as f:\n",
    "#    pickle.dump([lru_hitrates, lru_hitrate, lfu_hitrates, lfu_hitrate, opt_hitrates, opt_hitrate], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
