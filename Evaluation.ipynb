{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for Supervised Learning Cache Replacement Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from collections import Counter, deque, defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Cache Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum block number\n",
    "maxpos = 1000000000000\n",
    "\n",
    "# Number of features (Recency, Frequency, Block No.)\n",
    "num_params = 3\n",
    "\n",
    "# Cache Size\n",
    "cache_size = 100\n",
    "\n",
    "# Sequence Length\n",
    "sequence_length = 5\n",
    "\n",
    "# Storage\n",
    "sequence_data = np.zeros((sequence_length, cache_size, num_params))\n",
    "\n",
    "# How often to store the data (Removed currently)\n",
    "sampling_freq = cache_size\n",
    "\n",
    "# How many % of cache to use\n",
    "eviction = int(0.7 * cache_size)  \n",
    "\n",
    "# Results\n",
    "lruCorrect = 0\n",
    "lruIncorrect = 0\n",
    "\n",
    "lfuCorrect = 0\n",
    "lfuIncorrect = 0\n",
    "\n",
    "# Variables\n",
    "X = np.array([], dtype=np.int64).reshape(0,num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Shehbaz\n",
    "def get_recency(lru, cache):\n",
    "    recency = []\n",
    "    recency_dict = defaultdict(int)\n",
    "    \n",
    "    # Compute the recency order of each page in cache\n",
    "    for time in range(len(lru)):\n",
    "        recency_dict[lru[time]] = time + 1\n",
    "        \n",
    "    for block in cache:\n",
    "        recency.append(recency_dict[block])\n",
    "\n",
    "    return recency\n",
    "\n",
    "def get_frequency(lfu, cache):\n",
    "    frequency = []\n",
    "    \n",
    "    for block in cache:\n",
    "        frequency.append(lfu[block])\n",
    "    return frequency\n",
    "\n",
    "def normalize_columns(input):\n",
    "    return normalize(input, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_length_input(lfu, lru, cache, preprocess_func, cache_size):\n",
    "    input_recency = get_recency(lru, cache)\n",
    "    input_frequency = get_frequency(lfu, cache)\n",
    "    input_block_num = cache[:]\n",
    "    \n",
    "    if len(input_recency) < cache_size:\n",
    "        for i in range(0, cache_size - len(input_recency)):\n",
    "            input_recency.append(0)\n",
    "            input_frequency.append(0)\n",
    "            input_block_num.append(0)\n",
    "    \n",
    "    # Columns: recency, frequency, block number\n",
    "    # Row: cache location\n",
    "    raw_input = np.column_stack((input_recency, input_frequency, input_block_num))\n",
    "    \n",
    "    return preprocess_func(raw_input)\n",
    "\n",
    "\n",
    "SEQ_DIM = 0\n",
    "def get_multiple_length_input(sequence_length, prev_inputs, lfu, lru, cache, preprocess_func, cache_size):\n",
    "    assert prev_inputs.shape[SEQ_DIM] == sequence_length\n",
    "    current_input = get_single_length_input(lfu, lru, cache, preprocess_func, cache_size)\n",
    "    return np.vstack((prev_inputs[1:], current_input[None]))\n",
    "    \n",
    "\n",
    "def get_outputs(cache, delete):\n",
    "    assert(len(cache) == len(delete))\n",
    "    Y_current = []\n",
    "    KV_sorted = Counter(delete)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    assert(len(evict_dict) == eviction)\n",
    "    all_vals = evict_dict.values()\n",
    "    for e in cache:\n",
    "        if e in evict_dict.values():\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    assert((set(all_vals)).issubset(set(cache)))\n",
    "    return Y_current\n",
    "\n",
    "\n",
    "def store_pair(request_time, seq_len, seq_data, lfu, lru, cache, deleted, cache_size, preprocess_func):\n",
    "    global X,Y,Z\n",
    "    cache = list(cache)\n",
    "    Y_current = get_outputs(cache, deleted)\n",
    "    \n",
    "    Y = np.vstack((Y, np.array(Y_current)[None]))\n",
    "    X = np.vstack((X, seq_data[None]))\n",
    "    Z = np.vstack((Z, request_time))\n",
    "\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    return Y_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lruPredict(C,LRUQ,Y_OPT):\n",
    "    global lruCorrect, lruIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = len(LRUQ) - i\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lruCorrect+=1\n",
    "        else:\n",
    "            lruIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# returns sequence of blocks in prioirty order\n",
    "\n",
    "def Y_getBlockSeq(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argsort(x)\n",
    "    idx = idx[:eviction]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def Y_getMinPredict(Y_pred_prob):\n",
    "    x = []\n",
    "    for i in range(len(Y_pred_prob)):\n",
    "        x.append(Y_pred_prob[i][0])\n",
    "    x = np.array(x)\n",
    "    idx = np.argpartition(x, eviction)\n",
    "    \n",
    "    Y_pred = np.zeros(len(Y_pred_prob), dtype=int)\n",
    "    for i in range(eviction):\n",
    "        Y_pred[idx[i]] = 1\n",
    "    assert(Counter(Y_pred)[1] == eviction)\n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "def lfuPredict(C,LFUDict,Y_OPT):\n",
    "    global lfuCorrect, lfuIncorrect\n",
    "    Y_current = []\n",
    "    KV = defaultdict()\n",
    "    for e in C:\n",
    "        KV[e] = LFUDict[e]\n",
    "    KV_sorted = Counter(KV)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    for e in C:\n",
    "        if e in evict_dict:\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    for i in range(len(Y_current)):\n",
    "        if Y_current[i] is Y_OPT[i]:\n",
    "            lfuCorrect+=1\n",
    "        else:\n",
    "            lfuIncorrect+=1\n",
    "    return Y_current\n",
    "\n",
    "# return \"eviction\" blocks that are being accessed furthest\n",
    "# from the cache that was sent to us.\n",
    "\n",
    "def getY(C,D):\n",
    "    assert(len(C) == len(D))\n",
    "    Y_current = []\n",
    "    KV_sorted = Counter(D)\n",
    "    evict_dict = dict(KV_sorted.most_common(eviction))\n",
    "    assert(len(evict_dict) == eviction)\n",
    "    all_vals = evict_dict.values()\n",
    "    for e in C:\n",
    "        if e in evict_dict.values():\n",
    "            Y_current.append(1)\n",
    "        else:\n",
    "            Y_current.append(0)\n",
    "    #print (Y_current.count(1))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    assert((set(all_vals)).issubset(set(C)))\n",
    "    return Y_current\n",
    "\n",
    "def getLFURow(LFUDict, C):\n",
    "    x_lfurow = []\n",
    "    for e in C:\n",
    "        x_lfurow.append(LFUDict[e])\n",
    "    norm = x_lfurow / np.linalg.norm(x_lfurow)\n",
    "    return norm\n",
    "    \n",
    "def getLRURow(LRUQ, C):\n",
    "    x_lrurow = []\n",
    "    KV = defaultdict(int)\n",
    "    for i in range(len(LRUQ)):\n",
    "        KV[LRUQ[i]] = i\n",
    "    for e in C:\n",
    "        x_lrurow.append(KV[e])\n",
    "    norm = x_lrurow / np.linalg.norm(x_lrurow)\n",
    "    return norm\n",
    "\n",
    "def normalize(feature, blocks):\n",
    "    x_feature = []\n",
    "    for i in range(len(blocks)):\n",
    "        x_feature.append(feature[blocks[i]])\n",
    "    return x_feature / np.linalg.norm(x_feature)\n",
    "\n",
    "def getX(LRUQ, LFUDict, C):\n",
    "#def getX(LRUQ, LFUDict, C, CacheTS, CachePID):   \n",
    "    X_lfurow = getLFURow(LFUDict, C)\n",
    "    X_lrurow = getLRURow(LRUQ, C)\n",
    "    X_bno    = C / np.linalg.norm(C)\n",
    "#     X_ts     = normalize(CacheTS, C)\n",
    "#     X_pid    = normalize(CachePID, C)\n",
    "    return (np.column_stack((X_lfurow, X_lrurow, X_bno)))\n",
    "    \n",
    "    \n",
    "def populateData(LFUDict, LRUQ, C, D):\n",
    "#def populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID):\n",
    "    global X,Y\n",
    "    C = list(C)\n",
    "    Y_current = getY(C, D)\n",
    "    #X_current = getX(LRUQ, LFUDict, C, CacheTS, CachePID)\n",
    "    X_current = getX(LRUQ, LFUDict, C)\n",
    "\n",
    "    Y = np.append(Y, Y_current)\n",
    "    X = np.concatenate((X,X_current))\n",
    "    assert(Y_current.count(1) == eviction)\n",
    "    return Y_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belady Optimal Algorithm (From Shehbaz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    global maxpos, sequence_data, sequence_length\n",
    "    \n",
    "    optimal = defaultdict(deque)\n",
    "    deleted = defaultdict(int)\n",
    "    lfu = defaultdict(int)\n",
    "    lru = []\n",
    "\n",
    "    # Build the whole index for finding optimal eviction ordering\n",
    "    for request_time, block in enumerate(tqdm(blocktrace, desc=\"OPT: building index\")):\n",
    "        optimal[block].append(request_time)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    cache = []\n",
    "    \n",
    "    for request_time, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "        old_seq = sequence_data[:]\n",
    "        # increase frequency count\n",
    "        lfu[block] +=1\n",
    "\n",
    "        # Remove the block i at time step j from the index\n",
    "        if len(optimal[block]) is not 0 and optimal[block][0] == request_time:\n",
    "            optimal[block].popleft()\n",
    "\n",
    "        \n",
    "        if block in cache:\n",
    "            # Cache Hit\n",
    "            # Update block to MRU position\n",
    "            hit += 1\n",
    "            lru.remove(block)\n",
    "            lru.append(block)\n",
    "            \n",
    "            assert request_time in deleted\n",
    "            \n",
    "            del deleted[request_time]\n",
    "            if len(optimal[block]) is not 0:\n",
    "                deleted[optimal[block][0]] = block\n",
    "                optimal[block].popleft()\n",
    "            else:\n",
    "                deleted[maxpos] = block\n",
    "                maxpos -= 1\n",
    "            sequence_data = get_multiple_length_input(sequence_length, sequence_data, lfu, lru, cache, lambda x: x, cache_size)\n",
    "        else:\n",
    "            # Cache Miss\n",
    "            miss += 1\n",
    "            if len(cache) == frame:\n",
    "                # Cache is full\n",
    "                assert(len(deleted) == frame)\n",
    "                evictpos = max(deleted)\n",
    "                \n",
    "                #if (seq_number % sampling_freq +1 == sampling_freq):\n",
    "                y_opt = store_pair(request_time, sequence_length, sequence_data, lfu, lru, cache, deleted, cache_size, lambda x: x)\n",
    "    \n",
    "                cache[cache.index(deleted[evictpos])] = block\n",
    "                lru.remove(deleted[evictpos])\n",
    "                del deleted[evictpos]\n",
    "            else:\n",
    "                # Cache isn't full\n",
    "                cache.append(block)                \n",
    "            \n",
    "            # Add the candidate victim page to the j'th time step\n",
    "            if len(optimal[block]) is not 0:\n",
    "                deleted[optimal[block][0]] = block\n",
    "                optimal[block].popleft()\n",
    "            else:\n",
    "                deleted[maxpos] = block\n",
    "                maxpos -= 1\n",
    "            lru.append(block)\n",
    "            sequence_data = get_multiple_length_input(sequence_length, sequence_data, lfu, lru, cache, lambda x: x, cache_size)\n",
    "\n",
    "\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training or testing (evaluating) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### online.cs.fiu.edu-09 (casa-09)\n",
    "percentage:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47836"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = \"FIU_trace/cheetah.cs.fiu.edu-110108-113008.2.blkparse\"\n",
    "train = \"online.cs.fiu.edu-110108-113008.9.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.1)]\n",
    "# trainBlockTrace = trainBlockTrace[:300]\n",
    "# df.head()\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47836"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_casa09 = \"online.cs.fiu.edu-110108-113008.9.blkparse\"\n",
    "\n",
    "df = pd.read_csv(test_casa09, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "testBlockTrace_casa09 = df['blockNo'].tolist()\n",
    "testBlockTrace_casa09 = testBlockTrace_casa09[:int(len(testBlockTrace_casa09)*0.1)]\n",
    "# trainBlockTrace = trainBlockTrace[:300]\n",
    "len(testBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f311e612786b4b579bd36c0b598630da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT: building index', max=47836, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6acb696bd8641119e8215a3ac7a61b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=47836, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([], dtype=np.int64).reshape(0, sequence_length, cache_size, num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0, cache_size)\n",
    "Z = np.array([], dtype=np.int32).reshape(0, 1)\n",
    "trainHitrate = belady_opt(trainBlockTrace, cache_size)\n",
    "X_train = X\n",
    "Y_train = Y\n",
    "\n",
    "# training_data_file = 'fiu_01.pkl'\n",
    "training_data_file = 'online_09.pkl'\n",
    "with open(training_data_file, 'wb+') as f:\n",
    "    pickle.dump([X, Y, Z], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### online.cs.fiu.edu-12 (casa-12)\n",
    "percentage:0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52358"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = \"online.cs.fiu.edu-110108-113008.12.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.05)]\n",
    "# trainBlockTrace = trainBlockTrace[:300]\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_casa12 = \"online.cs.fiu.edu-110108-113008.12.blkparse\"\n",
    "\n",
    "df = pd.read_csv(test_casa12, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "testBlockTrace_casa12 = df['blockNo'].tolist()\n",
    "testBlockTrace_casa12 = testBlockTrace_casa12[:int(len(testBlockTrace_casa12)*0.05)]\n",
    "# trainBlockTrace = trainBlockTrace[:300]\n",
    "len(testBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ec9ad86b924b6da48ba5349d394d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT: building index', max=52358, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8188ac404a6041109e1bcf37e4a250dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=52358, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([], dtype=np.int64).reshape(0, sequence_length, cache_size, num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0, cache_size)\n",
    "Z = np.array([], dtype=np.int32).reshape(0, 1)\n",
    "trainHitrate = belady_opt(trainBlockTrace, cache_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webmail+online.cs.fiu.edu-12 (cheetah-12)\n",
    "percentage:0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52370"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = \"webmail+online.cs.fiu.edu-110108-113008.12.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.025)]\n",
    "# trainBlockTrace = trainBlockTrace[:300]\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c5924b37694e27a22d54400c048b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT: building index', max=52370, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c88c1e82e1a4858ad2114c468ecc044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=52370, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([], dtype=np.int64).reshape(0, sequence_length, cache_size, num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0, cache_size)\n",
    "Z = np.array([], dtype=np.int32).reshape(0, 1)\n",
    "trainHitrate = belady_opt(trainBlockTrace, cache_size)\n",
    "X_train = X\n",
    "Y_train = Y\n",
    "\n",
    "# training_data_file = 'fiu_01.pkl'\n",
    "training_data_file = 'webmail_12.pkl'\n",
    "with open(training_data_file, 'wb+') as f:\n",
    "    pickle.dump([X, Y, Z], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webmail+online.cs.fiu.edu-16 (cheetah-16)\n",
    "percentage:0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47275"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = \"webmail+online.cs.fiu.edu-110108-113008.16.blkparse\"\n",
    "\n",
    "df = pd.read_csv(train, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "\n",
    "trainBlockTrace = df['blockNo'].tolist()\n",
    "trainBlockTrace = trainBlockTrace[:int(len(trainBlockTrace)*0.05)]\n",
    "# trainBlockTrace = trainBlockTrace[:300]\n",
    "len(trainBlockTrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfd8b07e20c4eb98b1d30af7d9fae0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT: building index', max=47275, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea099ac66d474e7394e4006caf0f37ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='OPT', max=47275, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([], dtype=np.int64).reshape(0, sequence_length, cache_size, num_params)\n",
    "Y = np.array([], dtype=np.int64).reshape(0, cache_size)\n",
    "Z = np.array([], dtype=np.int32).reshape(0, 1)\n",
    "trainHitrate = belady_opt(trainBlockTrace, cache_size)\n",
    "X_train = X\n",
    "Y_train = Y\n",
    "\n",
    "# training_data_file = 'fiu_01.pkl'\n",
    "training_data_file = 'webmail_16.pkl'\n",
    "with open(training_data_file, 'wb+') as f:\n",
    "    pickle.dump([X, Y, Z], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRU, LFU and Belady methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belady (OPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    global maxpos\n",
    "    \n",
    "    OPT = defaultdict(deque)\n",
    "    D = defaultdict(int)\n",
    "    LFUDict = defaultdict(int)\n",
    "    LRUQ = []\n",
    "    #CacheTS = defaultdict(int)\n",
    "    #CachePID = defaultdict(int)\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"OPT: building index\")):\n",
    "        OPT[block].append(i)\n",
    "\n",
    "    hit, miss = 0, 0\n",
    "\n",
    "    C = []\n",
    "    #count=0\n",
    "    #seq_number = 0\n",
    "#     f = open(\"Belady_online12_evaluation.txt\",\"w+\")\n",
    "    f = open(\"Belady_online09_evaluation.txt\",\"w+\")\n",
    "    for seq_number, block in enumerate(tqdm(blocktrace, desc=\"OPT\")):\n",
    "        LFUDict[block] +=1\n",
    "\n",
    "        if len(OPT[block]) is not 0 and OPT[block][0] == seq_number:\n",
    "            OPT[block].popleft()\n",
    "        #CacheTS [blocktrace[seq_number]] = timestamp[seq_number]\n",
    "        #CachePID [blocktrace[seq_number]] = pid[seq_number]\n",
    "        if block in C:\n",
    "            hit+=1\n",
    "            LRUQ.remove(block)\n",
    "            LRUQ.append(block)\n",
    "            assert( seq_number in D)\n",
    "            del D[seq_number]\n",
    "            if len(OPT[block]) is not 0:\n",
    "                D[OPT[block][0]] = block\n",
    "                OPT[block].popleft()\n",
    "            else:\n",
    "                D[maxpos] = block\n",
    "                maxpos -= 1\n",
    "        else:\n",
    "            miss+=1\n",
    "            if len(C) == frame:\n",
    "                assert(len(D) == frame)\n",
    "                evictpos = max(D)\n",
    "                \n",
    "                if (seq_number % sampling_freq +1 == sampling_freq):\n",
    "                    #Y_OPT = populateData(LFUDict, LRUQ, C, D, CacheTS, CachePID)\n",
    "                    Y_OPT = populateData(LFUDict, LRUQ, C, D)\n",
    "                    lruPredict(C,LRUQ,Y_OPT)\n",
    "                    lfuPredict(C,LFUDict,Y_OPT)\n",
    "                \n",
    "                C[C.index(D[evictpos])] = block\n",
    "                LRUQ.remove(D[evictpos])\n",
    "                #del CacheTS [D[evictpos]]\n",
    "                #del CachePID [D[evictpos]]\n",
    "                del D[evictpos]\n",
    "            else:\n",
    "                C.append(block)\n",
    "                \n",
    "            if len(OPT[block]) is not 0:\n",
    "                D[OPT[block][0]] = block\n",
    "                OPT[block].popleft()\n",
    "            else:\n",
    "                D[maxpos] = block\n",
    "                maxpos -= 1\n",
    "            LRUQ.append(block)\n",
    "        if(seq_number%2000==0):\n",
    "#             f.write(\"%d\\n\" % seq_number)\n",
    "            f.write(\"%f\\n\" % (hit/(hit + miss)))\n",
    "    f.close()\n",
    "    hitrate = hit / (hit + miss)\n",
    "#     f = open(\"Belady_online12_evaluation.txt\",\"a+\")\n",
    "    f = open(\"Belady_online09_evaluation.txt\",\"a+\")\n",
    "#     f.write(\"%d\\n\" % seq_number)\n",
    "    f.write(\"%f\\n\" % hitrate)\n",
    "    f.close()\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    cache_frequency = defaultdict(int)\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "#     f_file = open(\"LFU_online12_evaluation.txt\",\"w+\")\n",
    "    f_file = open(\"LFU_online09_evaluation.txt\",\"w+\")\n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        if block in cache:\n",
    "            hit += 1\n",
    "            cache_frequency[block] += 1\n",
    "        \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] += 1\n",
    "            miss += 1\n",
    "\n",
    "        else:\n",
    "            e, f = min(cache_frequency.items(), key=lambda a: a[1])\n",
    "            cache_frequency.pop(e)\n",
    "            cache.remove(e)\n",
    "            cache.add(block)\n",
    "            cache_frequency[block] = frequency[block]\n",
    "            miss += 1\n",
    "            \n",
    "        if((hit+miss)%2000==0):\n",
    "#             f_file.write(\"%d\\n\" % (hit+miss))\n",
    "            f_file.write(\"%f\\n\" % (hit/(hit + miss)))\n",
    "    \n",
    "    f_file.close()\n",
    "    hitrate = hit / ( hit + miss )\n",
    "#     f_file = open(\"LFU_online12_evaluation.txt\",\"a+\")\n",
    "    f_file = open(\"LFU_online09_evaluation.txt\",\"a+\")\n",
    "#     f_file.write(\"%d\\n\" % (hit+miss))\n",
    "    f_file.write(\"%f\\n\" % hitrate)\n",
    "    f_file.close()\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRU(blocktrace, frame):\n",
    "    \n",
    "    cache = set()\n",
    "    recency = deque()\n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "#     f = open(\"LRU_online12_evaluation.txt\",\"w+\")\n",
    "    f = open(\"LRU_online09_evaluation.txt\",\"w+\")\n",
    "    for block in tqdm(blocktrace, leave=False):\n",
    "        \n",
    "        if block in cache:\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            hit += 1\n",
    "            \n",
    "        elif len(cache) < frame:\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "            \n",
    "        else:\n",
    "            cache.remove(recency[0])\n",
    "            recency.popleft()\n",
    "            cache.add(block)\n",
    "            recency.append(block)\n",
    "            miss += 1\n",
    "        \n",
    "        if((hit+miss)%2000==0):\n",
    "#             f.write(\"%d\\n\" % (hit+miss))\n",
    "            f.write(\"%f\\n\" % (hit/(hit + miss)))\n",
    "    f.close()\n",
    "    hitrate = hit / (hit + miss)\n",
    "#     f = open(\"LRU_online12_evaluation.txt\",\"a+\")\n",
    "    f = open(\"LRU_online09_evaluation.txt\",\"a+\")\n",
    "#     f.write(\"%d\\n\" % (hit+miss))\n",
    "    f.write(\"%f\\n\" % hitrate)\n",
    "    f.close()\n",
    "    return hitrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Belady, LFU and LRU methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casa-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belady_opt(testBlockTrace_casa09, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFU(testBlockTrace_casa09, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRU(testBlockTrace_casa09, cache_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casa-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belady_opt(testBlockTrace_casa12, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFU(testBlockTrace_casa12, cache_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRU(testBlockTrace_casa12, cache_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
